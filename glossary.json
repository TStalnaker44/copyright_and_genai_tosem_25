{
    "C5": {
        "Improved_Debugging": "AI code generation tools help with debugging",
        "Improved_Documentation": "AI code generation tools help with documentation tasks",
        "Provide_Inspiration": "Code generation tools can provide inspiration to developers and give them solution ideas",
        "Provide_Reference_or_Learning": "Code generation tools can act as a reference point for developers, by providing them with easy access to additional information about the codebase or library",
        "Writing_Basic_Code_Snippets": "Code generation models are good at generating code snippets that are basic, boilerplate, or used frequently",
        "Allows_to_Shift_Focus": "Code generation tools allow developers to focus more on interesting development problems and less on mundane or trivial tasks",
        "Lower_Costs": "The usage of code generation tools results in lower development costs",
        "Increases_Scope_of_Work": "The developer can work on more tools or complex projects because of AI assistance",
        "No_Response": "The participant did not respond to the question",
        "Generating_Test_Cases": "Generation tools help by generating test cases",
        "Generating_Test_Data": "AI tools can help by generating test data",
        "Linting": "AI tools can help find problems in code by \"linting\"",
        "Auto_Completion": "AI code generation tools provide (better) code auto-completion",
        "Refactoring_Code": "AI code generation models can help with refactoring code",
        "Experimenting": "Code generation models are good for experimenting with different ideas and potential solutions",
        "Getting_Alternatives": "Code generation tools are good for making and offering alternatives solutions or code logic",
        "Simplifying_Code_and_Logic": "AI code generation tools are good for simplifying code snippets or code logic",
        "Automate_Tasks": "Code generation tools help the developer to automate tasks that would otherwise be impractical or impossible",
        "Speed_Up_Architecture_Operations": "Provides speed up on architecture operations, like manipulating data in sql databases",
        "Quicker_Iterations": "Code generation tools allow for quicker iterations on projects",
        "Mistake_and_Typo_Correction": "Code generation tools help in correcting mistakes and typos",
        "Optimize_Existing_Solutions": "Code generation tools can be used to optimize existing, working solutions",
        "Rubber_Duck_Debugging": "AI tools can be used as next generation rubber duck debuggers",
        "Library_Selection": "Code generation tools can help developers find and use libraries for fields which they may not be familiar with",
        "Detection_of_Edge_Cases": "Code generation tools are helpful in detecting edge cases",
        "Improved_Testing": "Code generation models help with testing in general",
        "Assistance_with_Typing": "Code generation models provide assistance with types for typed languages",
        "Improve_Code_Quality": "Tools help to improve the quality of code (e.g. making solutions more efficient or following standard coding conventions, etc.)",
        "Pair_Programming": "AI code generation tools act as a pair programmer, catching issues and offering a different perspective",
        "Easy_to_Use": "Code generation tools are easy to use",
        "Security_Improvements": "Code generation tools offer suggestions for security improvements",
        "Porting_or_Translating_Code": "Help to port or translate code between platforms",
        "Domain_Logic_Support": "Can provide assistance when dealing with domain specific logic (insurance rates, formulae, etc)",
        "Can_Write_Better_Code_Than_Developer": "The tools are capable of (sometimes) generating code better than the developer prompting it",
        "Develop_in_Unfamiliar_Languages": "Tooling allows developers to work in languages they are not very familiar with",
        "Offers_a_Starting_Point": "Code generation tools offer a starting point better than starting from scratch",
        "Understanding_Errors": "Code generation models help developers understand the meanings of errors and exceptions",
        "In_Context_Solutions": "Code generation tools offer in-context solutions",
        "Learn_Best_Practices": "Code generation tools help developers to learn best practices",
        "Error_Detection": "Code generation models are good for detecting errors in projects",
        "Unsure": "The developer is unsure what benefits they have derived from code generation tools",
        "Performing_Repetitive_Tasks": "Generation tools are good for performing repetitive tasks",
        "No_Real_Benefits": "The respondent indicates that they haven't really obtained any benefits through the use of generative AI technologies",
        "Less_Fatigue_and_Burn_Out": "Using code generation tools results in less fatigue and developer burn out",
        "Incentive_to_Write_Good_Tests": "The use of code generation tools provides a good incentive to write good tests",
        "Code_Is_IDE_Ready": "Generated code is typically ready to be executed in an IDE",
        "Can_Explain_or_Summarize_Code": "Generative models are good at explaining or summarizing code",
        "Standard_and_Consistent_Code": "Generated code is standard and consistent in terms of style guides",
        "Offers_New_Perspective_or_Insight": "Generative models can offer novel perspectives or insights into how to solve problems",
        "Don't_Have_To_Read_Documentation": "The developer no longer has to read documentation in order to write code",
        "Less_Flow_State_Disruption": "Developers aren't pulled out of the \"zone\" by having to stop and read documentation",
        "Increased_Understanding": "The use of generative technologies has offered the developer an increased understanding of their domain, code base, or other technical aspect",
        "Can_Work_on_Bigger_Projects": "Code generation technologies have enabled the developer to work on bigger or more complex applications / projects that they otherwise would not have been able to",
        "Fast_Schema_and_Requirements": "Generative models are good at quickly generating schema or requirements for a project",
        "Fewer_Bugs": "Code generated by AI models has fewer bugs than that written by human developers",
        "Bad_Answer": "The answer is nonsensical or otherwise doesn't answer the question asked",
        "Data_Analysis": "Generative technologies are good for data analysis tasks",
        "Code_Review": "Generative technologies facilitate quicker and/or smoother code reviews",
        "Writing_Commit_Messages": "Generative technologies can write better, more informative commit messages",
        "Multimodel_Models": "Multimodal models provide ways of interacting with models that are more intuitive and useful",
        "Facilitate_Problem_Solving": "Code generation tools can facilitate better and faster problem solving",
        "Reduced_Cognitive_Load": "The developer notes that a decreased cognitive load, or not having to think, is a benefit of using generative technologies",
        "Implementing_Algorithms": "Generative code models help developers implement algorithms, calculations, and other code features more easily.",
        "Depends_on_the_Tool": "The benefits that the developer derives really depend on the tool being used",
        "Architecture_and_System_Design": "Generative models can help with the design of architecture and systems",
        "Accuracy": "The models produce accurate results and accurate code",
        "Less_Typing": "The usage of code generation tools allows the developer to type less",
        "Commit_Summarization": "Code generation models are great at summarizing the changes that happened in a commit",
        "Writes_Small_Scripts": "Generative code tools are great at making small scripts that work \"out-of-the-box\"",
        "Writing_Regex": "Code generation tools are good at writing regular expressions",
        "Lowers_Barrier_to_Entry": "Code generation models lower the barrier to entry",
        "Quickly_Move_From_Idea_to_Product": "Code generation tools help people quickly move from ideas to products",
        "Static_Analysis": "Code generation tools can be used for static analysis",
        "Quality_Assurance": "Generative technologies can be good at quality assurance tasks",
        "Faster_Configuring_of_Projects": "Generative AI models help to set up project configurations faster and easier",
        "Brainstorming": "Generative AI models are good for brainstorming ideas and solutions",
        "Eliminates_Scope_Creep": "The use of generative AI coding tools helps to eliminate feature and scope creep",
        "Reduce_Burden_of_Context_Switching": "When a developer is working on one or more projects using a variety of different programming languages, generative tools can help alleviate the burden of context switching by providing help with syntax",
        "Increased_Final_Product_Quality": "As the result of using generative technologies, the final product is of higher quality.  This could be because the tool provided better quality code or because the developer had more time to implement additional features and improvements",
        "Develop_with_Unfamiliar_Libraries": "AI code generation tools allow developers to work with libraries and tools they are not familiar with",
        "Less_Manual_Labor": "Developing while using generative technologies results in a reduction of manual labor and effort",
        "Create_Incident_Playbooks": "Generative technologies can be used to generate incident management playbooks",
        "Workflow_Improvements": "The introduction of generative technologies has led to workflow improvements",
        "Helps_when_Stuck": "Generative technologies can help developers when they get stuck and aren't sure how to proceed",
        "Makes_Certain_Tasks_Easier": "The developer expresses that generative technologies make some tasks easier, but they do not elaborate further",
        "Gives_Advice": "The developer can get good, sound advice from the code generation tool",
        "Like_a_Secretary": "Code generation models are like skilled secretaries",
        "Sounding_Board": "Generative models can act as a sort of sounding board for ideas and approaches",
        "Modularity": "The use of generative technologies increases modularity",
        "Explain_Obfuscated_Code": "Generative code models can help explain code that has been intentionally obscured or obfuscated",
        "Remember_Features_of_Code": "Generative AI technologies can help developers to remember the structure of their code bases and the variables they have made",
        "Making_UI": "Generative code models are good at creating user interfaces",
        "Understanding_Use_Cases": "Generative AI models can help with the understanding of use cases",
        "Safe_and_Secure": "Using generative AI tools makes code safer and/or more secure",
        "Adaptable": "Code generation tools are adaptable and can \"learn\" additional skills",
        "Helps_Solve_Complex_Problems": "AI code generation tools can help to solve complex or complicated problems",
        "Many_Benefits": "The respondent indicates that they have derived many benefits from using code generation models, but does not give any specific details or examples",
        "Integrated_into_Own_System": "The developer has integrated code generation model apis into their own systems or projects",
        "Explain_Concepts": "Generative models can explain or teach programming concepts to the developer",
        "Adaptive_Security": "Generative technologies can be used to create adaptive and learning security mechanisms",
        "Motivation": "Using code generation tools provides motivation",
        "Reproducibility": "Using code generation tools facilitates greater reproducibility",
        "Developer_Experience": "The respondent indicates in nonspecific terms that code generation tools improve the developer experience.",
        "Maintain_Conventions": "Code generation tools can help maintain conventions utilized in a given project, e.g. variable/method naming conventions",
        "Depends_on_the_Language": "Code generation tools' effectiveness is determined, at least in part, by the target language",
        "Writing_SQL_Queries": "Code generation tools are useful for writing SQL queries",
        "Prototyping_or_Skeleton": "AI code generation tools are good for prototyping and creating project outlines/skeletons",
        "Faster_Development_or_Saves_Time": "Code generation tools lead to faster development, saved time, and/or increased productivity"
    },
    "C6": {
        "Lack_of_Wider_Context": "Developers struggle to use code generation tools because they lack context on their code base",
        "Can't_Rely_On_AI_Fully": "Developers can't rely entirely on the AI code generation",
        "Have_to_Review_Carefully": "Developers have to review any generated code very carefully",
        "Trained_on_Old_Data": "Some AI models are trained on old data sets",
        "Unhelpful_or_Broken_Generations": "AI generation tools do not always produce useful or wanted code snippets.  Sometimes the snippets are broken or incomplete",
        "Generic_Generations": "Generated code is generic and / or basic",
        "Hallucinations": "Suggesting nonexistent methods, parameters, libraries, etc.",
        "Circular_Conversations": "Conversations with generation tools can become circular or repetitive",
        "No_Gaps": "The respondent indicated that they have not experienced any gaps or problems or that they were unsure or unaware of any problems",
        "No_Response": "The participant did not respond to the question",
        "AI_Doesn't_Understand_Problem": "The AI model doesn't correctly understand the problem the developer is trying to solve or the prompt the developer provided",
        "Bad_Answer": "Response states the obvious (restates the question as an answer) or is nonsensical",
        "Security": "Code generation models don't always produce code that is secure",
        "Generates_Poor_Quality_Code": "Generates code that is of poor quality (low efficiency, unnecessary portions, etc.)",
        "Speed": "The speed of code generation is a problem",
        "Incorporating_Generated_Code": "Struggle to incorporate generated code with the surrounding code context",
        "Doesn't_Work_for_Low_Code": "Code generation tools struggle to work with low code tools and frameworks (graphical / visual)",
        "Lacks_Visual_Reasoning": "Code generation tools lack visual reasoning skills",
        "Can't_Automate_End_to_End_Process": "We are currently unable to automate the end-to-end process of development",
        "Difficult_to_Go_From_Idea_to_Project": "It is difficult to easily go from ideas to a finished product that functions correctly and as intended",
        "Accuracy": "The code generations are inaccurate",
        "Over-Engineering": "Generated code includes too much detail and developers are forced to prune out all the unneeded portions",
        "Doesn't_Work_for_Complex_Issues": "You can't use code generation tools for complex problems",
        "Can't_Compete_with_Expert_Devs": "AI code generation models can't compare with developers who have years of experience",
        "Context_Window": "Limitations imposed by the size of the context window",
        "Must_Be_Able_to_Verify": "You can't use an AI model on anything that you would not be able to verify yourself",
        "Suggestions_Are_Not_Optimal": "Code generation tools can suggest suboptimal solutions",
        "Issues_Arising_from_Paid_APIs": "Concerns, other than cost, arise over the use of paid APIs",
        "Not_Trained_on_Most_Recent_Tech": "Tools are not trained on the latest technologies and software",
        "Lack_of_Transparency": "There is a lack of transparency in how the tools were trained, what data was used, and what the underlying source code is",
        "Truncates_Generated_Code": "Code generation models will sometimes truncate code instead of producing the full updated version, especially for large segments",
        "Not_Good_For_Debugging": "Code generation tools are not good for debugging code",
        "Doesn't_Really_Understand": "The models don't really 'understand'",
        "Outdated_Use_of_Packages": "Models provide uses with outdated uses of packages",
        "Lack_of_Language_Server_Integrations": "Code generation models lack language server integrations",
        "No_Control_Over_Result": "The developer laments that they have no real control over the result of generation",
        "Keeping_AI_Tools_Updated": "It is difficult and time consuming to make sure that AI tools are correctly updated",
        "Keeping_Up_to_Date_With_Advancements": "It is difficult and time consuming to keep up with AI advancements and the features that AI code generation tools are capable of",
        "Not_Smart_Enough": "The code generation tool just isn't smart enough to solve the problem",
        "Problems_That_Span_Files": "Code generation tools are not good at solving problems that span across multiple files",
        "No_Way_to_Partially_Accept_Solutions": "The tool in question does not provide an easy or intuitive way to accept only a part of the solution that is correct",
        "Cost": "The developer expresses that financial cost is an issue encountered when using code generation tools",
        "Generated_Code_Is_Deprecated": "The code generated by the model is deprecated",
        "Inconsistent_Results": "The results or responses given by the code generation model are inconsistent",
        "Poor_Test_Generation": "The test cases produced by code generation AIs are of poor quality or are otherwise unreliable",
        "Poor_Auto_Completion": "The wrong suggestions provided by the model are annoying and waste time",
        "Multiple_Generations": "Sometimes you have to try multiple times to get a good response from the model",
        "Trying_Different_Prompts": "Often developers may have to try multiple prompts to get the correct code generated",
        "Breaks_Code_on_Refactor": "During the process of refactoring, the code generation tool breaks the code",
        "Missing_Information": "The model is missing information / training data for tasks that are relevant to the developer",
        "Doesn't_Follow_Instructions": "The AI code generation tools do not follow the instructions provided by the developer",
        "Presume_Code_Function": "AI tools will be over presumptuous when describing what code does and is capable of",
        "Intrusive": "The suggestions by such tools are intrusive and get in the developer's way",
        "Off_Topic": "Sometimes the responses from AI code generation models are off topic and/or not related to the context or the question asked",
        "Generates_Buggy_Code": "The code generated by AI models can be or is often buggy",
        "Hurts_Developer_Skills": "Over-reliance and use of code generation tools can hurt the coding skills of developers",
        "Doesn't_Work_For_Less_Popular_Libraries": "Code generation tools struggle to provide correct code snippets when dealing with less popular libraries, languages, and frameworks",
        "Instructions_Need_to_be_Broken_Down": "Code generation tools require instructions to be broken down into small, easily understandable parts",
        "Subtle_or_Hidden_Errors": "Errors are introduced by code generation tools that are subtle or can be hard to readily identify",
        "Inability_to_Design": "Code generation tools lack the ability to create a complete design",
        "Mindset_Switch": "Code generation tools put developers into a different mindset (supervising / coordinating) which can be difficult to transition out of once things are no longer working",
        "Formatting_Issues": "The developer has issues with the format of generated code",
        "Must_Use_Good_Prompts": "Without the use of good, detailed prompts code generation tools will fail to produce high quality working code",
        "Too_Many_To_List": "The respondent states there are too many short-comings to list or elaborate on, but provides no further information",
        "Censored": "Models will refuse to comply with certain requests",
        "Generated_Code_Doesn't_Fit_Project": "The code that is generated by AI models doesn't always fit the project's dependencies or requirements",
        "Time_Consuming_to_Fix_Code": "It is time consuming to fix generated code effectively mitigating any benefits from using code generation tools",
        "Makes_Problems_Worse": "The use of code generation tools can make the problems the developer is trying to solve worse",
        "Ambiguities": "There are problems introduced by ambiguities in the meanings of terms or prompts",
        "Privacy": "Concerns over privacy are a problem encountered in the use of AI code generation technologies",
        "Lack_of_Creativity": "AI code generation models lack creativity and struggle to go beyond their training examples",
        "Hard_to_Understand_Generated_Code": "It can be hard to understand the code generated by AI models",
        "Interactivity_Problems": "Current tools do not support interactively updating only a few lines of a solution",
        "Verbose": "Responses from models are more verbose than required",
        "Multiple_Windows": "The developer would rather all functionality be confined to a single window",
        "Young_Technology": "Code generation tools are still a young technology and need more time to develop",
        "Licensing_Problems": "AI generated tools produce code that could lead to licensing, copyright, or plagiarism issues",
        "Autocomplete_Issues": "There are issues surrounding how code generation models try to autocomplete code.  This could mean that they jumping the gun and are suggesting long sections of code that are irrelevant",
        "Doesn't_Work_For_Usecase": "Code generation tools do not work the developers particular use case",
        "Unfounded_Confidence": "The code generation model exhibits a confidence in its responses that is unfounded, often promoting incorrect responses",
        "Long_Prompts": "The developer laments having to write long prompt so that the model can correctly understand the problem",
        "Doesn't_Ask_for_Clarification": "The AI code generation models guess at context and intent instead of asking follow up questions",
        "Network_Issues": "The developer has experienced network related issues when using code generation tools",
        "Not_Autonomous": "The developer has to work with the AI to help it resolve problems.  AI code generation tools can not go off on their own to solve problems and then report back",
        "Learning_Curve": "There is an initial learning curve involved in using code generation tools",
        "Not_Good_at_Documentation": "Code generation models are not good at writing accurate documentation",
        "Confused": "Sometimes the AI code generation models seem to get confused.  This could happen if the usage of a term in a program does not match its standard English definition",
        "Models_Can't_Test_Output": "Code generation models are incapable of testing their output for correctness before giving it to the user",
        "Models_Don't_Learn": "Models don't learn from past mistakes and experiences",
        "Can't_Provide_Sources": "Generative AI models can't provide sources for the content they generate",
        "Developer_Experience_Problems": "Generative AI technologies have developer experience problems such as poor integration into existing tools",
        "Edge_Cases": "Code generation models struggle with edge cases",
        "Domain_Issues": "There are issues involved in using code generation AI in niche or smaller domains",
        "Doesn't_Follow_Best_Practices": "Code generation AI models don't always follow best practices",
        "Inability_to_Optimize": "Code generation models have an inability to optimize existing code",
        "Blackbox_Problem": "No one really knows how LLMs work or why they provide certain responses",
        "Introduces_Code_Smells": "Code generation AI models introduce code smells into the codebase",
        "Not_for_Critical_Systems": "Code generation tools should not be used in critical systems",
        "Poor_Training_Data": "The data used to train code generation models was of low quality",
        "Garbage_in_Garbage_Out": "When code generation tools are used in a project that is poorly written, then the generations will also be of low quality",
        "Threat_to_Learning": "The over-reliance on code generation models may prevent developers from learning new languages or features",
        "Not_Good_at_UI": "Code generation AI models are not good at create UI elements",
        "Reasoning_Skills": "Code generation tools lack reasoning skills",
        "Needlessly_Complex_Solution": "The solution provided by the code generation model is more complex or convoluted than it needs to be",
        "Hardware_Related_Issues": "The respondent mentions issues related to hardware",
        "Have_to_Onboard_AI": "The AI model needs to be onboarded in order to understand the company / project",
        "Availability": "Not all code generation AI tools are available to everyone.  Based on geography, technical knowledge, or language / tools used",
        "Increases_Technical_Debt": "The use of code generation AI models increases technical debt for projects",
        "Produces_Redundant_or_Repetitive_Code": "Code produced by generative AI can be repetitive or redundant",
        "Not_Good_with_Math": "Generative technologies are not good with math and often provide incorrect results",
        "Tools_are_Getting_Worse": "Generative AI tools are only getting worse over time instead of improving",
        "Issues_with_Dimensionality": "AI code generation models may struggle as the dimensionality of the data increases",
        "Information_or_Data_Leaks": "The occurrence of information or data leaks is a problem",
        "Backtracking": "Once you have gone down a path with an AI code generation tool, it is difficult to backtrack",
        "Ethical_Issues": "There are ethical issues involved in the usage and training of code generation technologies",
        "Poorly_Documented": "Code generation tools do not have sufficient documentation",
        "Time_Consuming_to_Prompt": "It can be more time consuming to give generative AI enough inputs to correctly solve a problem than it would be to solve the problem itself.",
        "Depends_on_Scope": "The scope of the problem requested determines the success of generative AI models.",
        "Unsure": "The respondent is unsure of any problems or gaps with code generation AI models/tools",
        "Hard_to_Integrate_Into_Tool_Suite": "It is difficult to incorporate code generation AI into a developer's workflow along their existing development tools.",
        "Poorly_Trained_Model": "AI code generation models may be poorly trained, contributing to subpar outputs",
        "Limited_Support_Tools": "Few competent support tools exist to facilitate the use of code generated by AI models.",
        "Doesn't_Work_For_Legacy": "Code generation AI does not work well when asked to work in legacy code.",
        "Acceptance_of_Use": "The use of code generation AI models requires the approval or acceptance of stakeholders, such as executives, clients, etc.",
        "Niche_Solutions": "Solutions to problems are often too specific or niche and not generalizable",
        "Blind_Trust": "Developers tend to trust or rely on code generation models too much, to the point of potentially missing errors or oversights",
        "Requires_Manual_Edits": "Developers are forced to manually refactor or edit code generated by code models"
    },
    "C8": {
        "No_Usecase_or_Not_Useful": "The developer hasn't found a usecase or reason to incorporate code generation AI technologies into their workflow",
        "No_Response": "The participant did not respond to the question",
        "Webtools_are_Enough": "Chat-GPT and copy-paste are suitable enough",
        "Sending_Code_to_Remote": "Developer doesn't like the idea of sending code to a remote server in the cloud",
        "Models_Don't_Make_Good_Suggestions": "Merge with Low_Trust?",
        "Ethical_Considerations": "Code generation models aren't incorporated into the normal workflow for ethical reasons",
        "Prefer_to_Code_Themself": "The developer prefers to write the code themselves",
        "Wants_to_Undestand_Code": "Developer wants to understand the code that they add to their projects",
        "Doesn't_Use_Code_Directly": "The code that the AI produces isn't directly incorporated into the project, instead the developer uses it for inspiration or a starting point",
        "Not_Enough_Technical_Knowledge": "The developer doesn't have enough technical knowledge to incorporate AI code generation into their development workflow",
        "Can't_Evaluate_Cost_Effective_Solution": "The developer doesn't have time / resources to evaluate a cost effective solution for incorporating AI code generation models into the workflow",
        "New_to_Prompt_Engineering": "The developer is still learning how to effectively prompt engineer",
        "Doesn't_Add_Much_Value": "In the developer's estimation, code generation tools didn't add much value",
        "Low_Trust": "The developer doesn't trust the generated code for work projects",
        "Require_Extensive_Debugging": "The excessive debugging that is required to test and fix generated code defeats the purpose of using the tools",
        "Intrusive": "The suggestions by such tools are intrusive and get in the developer's way",
        "Not_Good_for_Complex_Problems": "Code generation tools are not good at solving complex problems",
        "Slower_Than_Coding_or_Other_Tools": "The developer finds it slower to use code generation tools than to just write the code themself",
        "Paywall": "The developer is deterred because of a paywall",
        "Performance": "The performance of code generation tools is a problem for the developer",
        "Code_Style": "Generated code does not match the desired style of the developer or their organization",
        "Employer": "Employer does not allow the use of code generation AI",
        "Privacy_Concerns": "The developer expresses privacy concerns",
        "Hallucinations": "Code generation tools tend to hallucinate",
        "Takes_the_Fun_Out_of_Coding": "Using code generation tools takes the fun out of coding",
        "Security_Concerns": "The developer has security concerns surrounding the usage of code generation models",
        "Discourages_Learning_Project": "The developer says that the use of code generation technologies discourages them from learning about their project and designing adequate solutions",
        "Uncertainty_About_Deploying_to_Production": "There is uncertainty surrounding the deploying of AI in production",
        "Incorrect_Code_Generations": "The code generated by AI tools is often incorrect",
        "Only_Use_For_Hard_to_Google_Cases": "The developer only use code generation tools for scenarios that are difficult to search for / find online",
        "Clients_Forbid_Them": "The developer's clients specifically forbid the use of code generation tools",
        "Not_Mature_Enough": "Code generation technologies are not mature enough yet",
        "Concerns_About_Training": "The developer expresses concerns about how the code generation models were trained",
        "Doesn't_Want_to_Become_Dependent": "The developer doesn't want to become overly dependent on the tools",
        "Doesn't_Work_For_Use_Case": "The developer expresses that code generation tools wouldn't work well for their use case (i.e. a highly customized code base or large existing system)",
        "Still_Have_to_Check_Code": "The developer would still have to verify and validate all code generated by the tool which would be a time consuming process",
        "Other_Priorities": "Other, sometimes competing, priorities have kept the developer from incorporating code generation tools into their workflow",
        "Legal_Risks": "Legal risks in general are a concern for the developer",
        "Doesn't_Want_to_Get_Rusty": "The developer doesn't want to lose the skills they spent years building",
        "Not_Good_For_Novel_Problems": "Code generation models are not good for solving novel problems",
        "Doesn't_Work_For_Less_Popular_Languages": "Code generation models struggle for less popular languages",
        "Alternatives_are_Sufficient": "Existing tools/strategies already provide benefits equal to or greater than what code generation tools offer.",
        "Bad_Publicity": "Using such models or the consequences of using such models could attract unwanted negative publicity.",
        "Haven't_Incorporated_Yet": "Has not incorporated code generation into current workflow, but may do so in the future"
    },
    "C12": {
        "No_Response": "The participant did not respond to the question",
        "Legal_Risk": "The employer does not allow the use of AI code generation tools because of potential legal risks involving the data used in training",
        "Sensitive_Information_or_IP": "The employer / organization / client(s) deals with sensitive information or wants to protect their IP",
        "Not_Sure": "The developer is unsure why their employer does not allow them to use code generation tools",
        "Security": "Code generation tools are not allowed for security reasons",
        "Hasn't_Been_Cleared_Yet": "The use of code generation tools hasn't been cleared yet, but presumably will be at some point",
        "Domain_of_Work": "The area or sector in which the developer works is the reason they are not allowed to use code generation tools",
        "Slow_to_Adopt": "The employer or organization is slow to adopt new technologies",
        "Doing_Fine_Without_It": "The company or organization is doing fine without code generation technologies",
        "Issues_Over_Code_Authorship": "The employer doesn't allow code generation tools because there are still over questions of code ownership",
        "Threat_to_Human_Intellect": "The use of code generation technologies poses a threat to the human intellect",
        "Unexpected_Code_Behavior": "The behavior of code generated by AI tools can sometimes be unexpected",
        "Standards": "Employer or organization does not allow the use of code generation tools due to some standards like ISO or SOC2",
        "Bad_Answer": "The answer is nonsensical or otherwise doesn't answer the question asked",
        "Quality": "Employer has quality concerns with using code generation technologies",
        "Reliability": "The employer is concerned about the reliability of solutions produced using code generation technologies",
        "May_Impact_Programmer_Skills": "Employer fears that the use of AI technologies may negatively impact programmer skills",
        "Employer_Doesn't_Understand_Benefits": "The employers doesn't understand the benefits of using such a technology"
    },
    "U14": {
        "Legal_Issues_Surrounding_Training_Data": "There will likely be legal issues surrounding the training data used to make generative AIs",
        "Code_Repair": "Legal issues could arise if code generation is used for code repair",
        "Unemployment": "A social problem that will arise is the unemployment or laying off of programmers or other workers",
        "Information_Leaks": "The leakage of PII, IP, or other sensitive information is a potential issue",
        "Not_Sure_or_No_Issues": "The respondent is not sure or couldn't think of any issues",
        "Server_Side_YML_Files": "Legal issues could arise in the creation of server side YML files",
        "Documenting_Test_Cases": "Legal issues could arise in the documenting of test cases",
        "No_Response": "The participant did not respond to the question",
        "Hate_Thinking_About_It": "The respondent would rather not think about the legal ramifications of using AI technologies",
        "Other_Media_Generation": "Legal concerns will also be relevant to the generation of images, videos, audio, and other types of media",
        "Testing": "Legal issues will arise in testing when using AI code generation tools",
        "Data_in_Code": "Legal issues will arise surrounding the data in the code",
        "Shell_Command_Generation": "Issues surrounding the use of generative technologies to create shell commands and running them on production servers with reliability agreements",
        "UI_Related": "The reliance on generative technologies for UX and UI design will lead to similar if not identical end products",
        "Requirements": "Legal issues could present themselves in the determining and specifying of project requirements",
        "Bad_Answer": "The answer is nonsensical or otherwise doesn't answer the question asked",
        "Authoring": "Legal issues will arise as developers use generative technologies to write books and articles",
        "Generation_For_Scams": "Legal issues will arise when generation technologies are used for scams (voice cloning, fake images, etc.)",
        "Product_Liability": "The addition of LLMs and generation technologies will introduce all sorts of new problems to products",
        "Plagiarism_and_Imitation": "Concerns will arise over plagiarism and imitation of style",
        "Generation_of_Legal_Documents": "The generation of legal documents such as ToS and Eula could be problematic",
        "Not_Concerned": "Developer really isn't concerned about potential legal issues",
        "Architecture_Design": "Code generation tools could lead to legal issues relating to the design of software architectures and structures",
        "Web_Scraping": "Advanced web scraping that uses generative AI and doesn't respect the robots.txt file or ToS could lead to legal issues",
        "Documentation": "Legal issues can arise in the generation of documentation",
        "Liability_for_Generated_Bugs_and_Defects": "The liability assumed by parties involved in the generation of codes with bugs or broken features is still an open question",
        "Bias": "AI models have bias depending on their training data.  This can manifest in many ways including discrimination in hiring",
        "Automation": "Legal issues arising do to the incorporation of business automation strategies",
        "Content_Copyrights": "Issues will arise over the copyrights of content",
        "Code_Reviews": "Legal issues may surround the accuracy and completeness of code and logic reviews",
        "All_Tasks": "The models will introduce risks in the same ways that humans do to many, if not all, tasks",
        "Chatbots": "Legal issues will arise surrounding chatbots and other client facing uses of AI",
        "Patents": "Issues related to patents will arise, particularly patented code segments or patenting new algorithms designed using generative technologies",
        "Cryptography": "Generation models will introduce legal risks in the area of cryptography",
        "Open_Source": "Legal challenges and questions will be brought up as it regards open source",
        "Break_Standards_and_Regulations": "The use of code generation AIs could lead to non-compliance with industry standards or other regulations",
        "Decision_Making": "Using generative technologies to help make decisions can lead to legal risks",
        "Generated_ML_Networks": "Legal questions will arise over the creation of machine learning networks designed by generative technologies",
        "Developers_Sleep_at_Wheel": "The use of AI technologies will result in developers not testing or reviewing the code being put into production",
        "Use_in_Critical_Systems": "The use of generative technologies in critical systems is likely to result in legal issues",
        "Generating_Synthetic_Data": "Legal issues will arise in the creation of synthetic data",
        "Hacking": "Hacking facilitated by the use of code generation AIs",
        "AI_Revoked": "The AI systems that developers rely on are suddenly removed or access to them is otherwise disrupted",
        "Reverse_Engineering": "AI generation models could be used to facilitate reverse engineering, leading to legal issues",
        "Education": "Legal issues will arise surrounding generative AI and education",
        "Language_Translation": "Legal issues will arise when translating code from one language to another",
        "Abuse_Leads_to_Restrictions": "The abuse of AI technologies by a few individuals will result in restrictions on everyone",
        "Toxic_Content": "The content generated by the AI model is toxic or otherwise repugnant, sometimes to legal effect (i.e. Nazi propaganda generated in some European countries)",
        "Misleading_Content": "The content generated by the AI model is misleading, resulting in some type of loss.  This could be medical or legal advice",
        "The_Law_Will_Change": "The very nature of this tech revolution will cause the legal system to change",
        "Law_Is_Too_Slow": "The current legal system is too slow to keep up with advances in the technology sector",
        "Conformity_Assessment": "The use of generative technologies in conformity assessments could lead to legal issues",
        "Liability_For_AI_Agent_Actions": "Liability for actions taken by a generative AI.  These actions are separate from the content generated.  This considers functions or APIs directly called by the model or tool",
        "Jail_Breaking": "Generative AI technologies may enable the jailbreaking of software",
        "Automated_Data_Analysis": "Legal issues will arise as generative tools are used to perform automated data analysis",
        "Workflow_Generation": "The generative tools create a workflow and / or plan for completing projects",
        "AI_Influencers": "The creation and use of AI influencers (e.g. Lil' Miquela) will result in legal issues",
        "Lawyers_Will_Decide": "Lawyers and litigious clients will sue whenever and however they want, meaning that legal issues could always be present",
        "Generating_Malicious_Content": "The use of generative technologies to generate malicious content will result in legal issues.  Examples include fake news, defamation, cyber-bullying, toxic content, illegal images, malware, etc.",
        "Generative_Models_Don't_Lead_To_Legal_Issues": "The use of generative models alone does not lead to legal issues.  Humans using the tools carelessly create legal problems",
        "Breaching_NDA": "Using generative technologies could breach NDAs",
        "Entertainment": "Generative technologies will create legal issues in the realm of entertainment generally",
        "Gamification": "Legal issues will arise as generative technologies are used in the process of gamification",
        "Management": "Generative models that are used in the management process could result in legal issues",
        "Data_Privacy": "Concerns surrounding data privacy will become important legal problems",
        "Training_Set_Leak": "The entire dataset that a model was trained on is somehow leaked",
        "Marketing": "The usage of generative AI in marketing could result in legal issues",
        "Research": "Using generative technologies in the context of academic or industrial research could result in legal issues",
        "Impersonation": "Generative models can be used to impersonate people to great effect, leading to legal issues",
        "Rogue_Agents": "Models / tools that are able to self prompt and go rogue, producing malicious content",
        "Design_Patterns": "Legal issues could arise surrounding the creation or use of design patterns using generative AI",
        "Algorithms": "Legal issues could arise surrounding the creation or use of algorithms using generative AI",
        "Data_Structures": "Legal issues could arise surrounding the creation or use of data structures using generative AI",
        "Product_Design": "Legal issues could result if generative technologies are used during the design of a product",
        "Generation_of_Task_Descriptions": "The generation of task descriptions could lead to legal issues",
        "Generation_of_Business_Models": "Legal issues could arise with the generation of business models",
        "Composing_Ones_Thoughts": "Generative models used in the capacity to compose and refine one's thoughts",
        "License_Compliance": "Complying with the licenses of software when using AI generated code will be difficult",
        "AI_Detection_Tools": "Issues, including legal, will arise with the use of AI detection tools, particularly if those tools are also AI",
        "Prototyping": "Using generative AI tools for creating prototypes and mockups could result in legal challenges",
        "Protected_Info_In_Prompt": "Legal issues could arise if protected or copyrighted information is put into a prompt to a code generation model",
        "AI_No_Different_Than_Humans": "Fundamentally AI is no different than a human with respect to learning",
        "Penetration_Testing": "Legal issues could arise when using generative models for penetration testing",
        "No_Lawyers_Until_Tech_Matures": "We should wait until the technology matures before we bring in the lawyers",
        "References_Firm_Company_Or_Name": "Explicit references to companies, firms, brands, or other names could result in legal issues",
        "Continuous_Integration": "The use of generative technologies in the CI/CD pipeline could result in legal issues",
        "AI_Security_Audits": "Relying on AI tools to complete security audits could be problematic",
        "Cloud_Infrastructure": "Allow generative technologies to manage the operations of cloud infrastructure could prove problematic",
        "Jail_Breaking_LLMs": "The jail breaking of LLMs to bypass safety rules could lead to legal challenges",
        "Code_Execution": "Legal challenges could arise of generative models ability to execute code",
        "DevOps": "Legal challenges could arise in the use of generative AI for DevOps tasks",
        "Issue_Triage": "Using generative technologies in the process of issue triage could result in legal issues",
        "Citing_of_Sources": "The very act of citing sources could lead to legal problems",
        "Generating_Poor_Quality_Code": "Generating poor quality or unmaintainable code could lead to legal issues",
        "Generating_Copyrighted_Content": "If the model generates content that is or has been inspired by copyrighted content, legal issues are likely",
        "Generating_Use_Cases": "Using generative technologies to determine or create use cases could result in legal challenges",
        "Right_of_Removal": "Entities should have the right to have their data removed from training sets",
        "Generated_Content_Can't_Be_Copyrighted": "Content generated by an artificial intelligence can not be copyrighted",
        "The_Future_is_Now": "The respondent expresses the sentiment that the future has come and cannot be stopped.  People need to either accept it, get out of the way, or be made obsolete.",
        "Ownership": "Disputes will naturally arise over who owns AI generated content",
        "Generation_of_SDKs": "The generation of SDKs could result in legal issues",
        "Evasive_Tools": "The tendency of tools to evade or dodge programmer questions could lead to legal disputes",
        "Infrastructure_as_Code": "Legal challenges will arise around the use of infrastructure as code",
        "Prompt_Injection_Attacks": "Prompt injection attacks will cause legal issues",
        "Attribution": "Attribution, or lack thereof, will present legal challenges",
        "Use_of_Proprietary_API_or_Systems": "A generative model's use of proprietary systems and APIs could result in legal challenges",
        "Use_of_Input_to_Train_Model": "If user inputs are used to train the model, legal disputes will likely arise",
        "Refactoring": "Using generative AI for refactoring tasks could lead to legal challenges",
        "Generating_Substitutes": "Generative technologies can be used to create substitutes to existing services (forums, newspapers, etc) by explicitly copying their content",
        "Interpreting_Legal_Docs_or_Regulations": "Using generative technologies to interpret legal documents or regulations could lead to issues",
        "Generating_Specifications": "Using generative technologies to write project specifications can lead to legal issues",
        "Transparency": "Transparency, or lack thereof, could result in legal issues",
        "Framework_Barriers": "Barriers to using particular frameworks could result in legal challenges",
        "Debugging": "The use of generative technologies for debugging tasks could result in legal challenges",
        "Corporate_Espionage": "Using AI tools to gain internal, private insights about a company, organization, or competitor",
        "Data_Modeling": "The use of generative technologies for the task of data modeling could raise issues",
        "Job_Interviews": "Using generative technologies to prepare for or during job interviews could raise legal challenges",
        "Generation_of_Issues": "The use of generative technologies to create issues could lead to legal challenges",
        "Issue_Tracking": "Using generative technologies in the process of issue tracking can introduce legal issues",
        "Accessibility_Compliance": "Code generated by models may not be meet accessibility compliance requirements",
        "Issues_with_Sending_to_Remote": "Legal issues surrounding privacy and data use will arise when data is being sent to a remote model",
        "Mistrust_Of_Establishment": "The respondent expresses a mistrust in the establishment, specifically as it relates to being able to accurately and fairly decide legal cases",
        "Similarity_of_Ideas": "If ideas are similar, even if the code is different, legal issues could still arise",
        "Uncharted_Waters": "The response indicates that we are in uncharted waters (legally) without providing further details",
        "Medical_Domain": "The use of generative AI in healthcare or for medical applications could lead to legal risk.",
        "Legal_Practice": "Using generative AI in legal practice itself can cause legal issues.",
        "Configuration": "Legal issues could arise from using generative AI for configuring software.",
        "Using_Code_Correctly": "Legal issues could arise from using AI generated code incorrectly, for reasons other than it was designed for, or that is outdated based on when the model was trained.",
        "Process_Management": "Legal issues could arise from the use of AI generation tools in relation to process management.",
        "Human_Resources": "The use of generative AI in human resources tasks like hiring could lead to legal issues.",
        "Self_Driving_Vehicles": "AI generations tools could lead to legal issues where they relate to self-driving vehicles and their safety.",
        "SEO_Hacking": "Legal issues could arise from using generative AI in tasks related to search engine optimization",
        "Version_Control_Related": "Questions surrounding version control commit messages, merge requests, and appropriately assigning blame",
        "Generating_Licenses": "Using generative technologies to write software licenses could lead to legal questions and issues",
        "Security_Issues_in_Generated_Code": "Security issues arising from sub-optimal or poor choices made by AI code generation tools"
    }
}